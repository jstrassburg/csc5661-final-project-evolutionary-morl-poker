{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec10883e",
   "metadata": {},
   "source": [
    "# Evolutionary Multi-Objective Reinforcement Learning for Texas Holdem\n",
    "\n",
    "In this notebook, I will:\n",
    "\n",
    "- Define an environment to represent the game of fixed-limit Texas Holdem\n",
    "- Create six agents:\n",
    "  - Four to represent the well-known poker player archetypes: \n",
    "    - Tight-aggressive (TAG) - A normally tight player who gets aggressive with quality hands.\n",
    "    - Loose-aggressive (LAG) - A player who aggressively plays lots of hands regardless of quality.\n",
    "    - Loose-passive (calling station) - A player who plays lots of pots but doesn't aggressively raise quality hands.\n",
    "    - Tight-passive (nit or rock) - A player who plays few hands and only commits chips with quality hands.\n",
    "  - And two to represent our RL trained agents.\n",
    "\n",
    "The RL trained agents will use an evolutionary (genetic) algorithm and evolutionary reinforcement learning techniques. One will be single objective (single policy to maximize winnings) and the other will be multi-objective (a different policy for each of the playing styles noted above).\n",
    "\n",
    "I will then compare the performance of the single-objective agent to the multi-objective agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import deque\n",
    "from collections.abc import Iterable\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pokerkit import (Automation, Card, Deck, FixedLimitTexasHoldem, Rank,\n",
    "                      StandardHighHand, Suit, calculate_hand_strength,\n",
    "                      parse_range)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0804763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the available actions that a player can take\n",
    "# when it is their turn to act.\n",
    "class ActionType(Enum):\n",
    "    FOLD = 0\n",
    "    CHECK_OR_CALL = 1\n",
    "    BET_OR_RAISE = 2\n",
    "\n",
    "# The different streets in Texas Hold'em\n",
    "class StreetType(Enum):\n",
    "    PRE_FLOP = 0\n",
    "    FLOP = 1\n",
    "    TURN = 2\n",
    "    RIVER = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f730eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokerEquityCalculator:\n",
    "    \"\"\"\n",
    "    Utility class to calculate the strength of a given hand\n",
    "    on a given board using Monte Carlo simulations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        # self._executor = ProcessPoolExecutor()\n",
    "        pass\n",
    "\n",
    "    def calculate_strength(\n",
    "        self,\n",
    "        hand: Iterable[Iterable[Card]],\n",
    "        board: Iterable[Card],\n",
    "        players_left_in_hand: int = 5,\n",
    "        sample_count: int = 1000,\n",
    "    ) -> float:\n",
    "        return calculate_hand_strength(\n",
    "            player_count=players_left_in_hand,\n",
    "            hole_range=hand,\n",
    "            board_cards=board,\n",
    "            hole_dealing_count=2,\n",
    "            board_dealing_count=5,\n",
    "            deck=Deck.STANDARD,\n",
    "            hand_types=(StandardHighHand,),\n",
    "            sample_count=sample_count,\n",
    "            # executor=self._executor,\n",
    "        )\n",
    "\n",
    "    def __del__(self) -> None:\n",
    "        if self._executor:\n",
    "            self._executor.shutdown(wait=True)\n",
    "            self._executor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a8bd1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservableState:\n",
    "    \"\"\"Represents the observable state for a player making game-time decisions.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hand: Iterable[Iterable[Card]],  # The player's hole cards\n",
    "        board: Iterable[Card],  # Any cards on the board\n",
    "        can_fold: bool,  # If the player can fold\n",
    "        can_check_or_call: bool,  # If the player can check or call\n",
    "        can_complete_bet_or_raise_to: bool,  # If the player can bet or raise\n",
    "        players_left_in_hand: int,  # Number of players left in the hand\n",
    "        hand_strength: float,  # The strength of the player's hand based on who's left and the board\n",
    "        pot_size: int,  # Current size of the pot\n",
    "        checking_or_calling_amount: int,  # Amount needed to check or call\n",
    "        min_completion_betting_or_raising_to_amount: int,  # Minimum amount to bet or raise to\n",
    "        street: StreetType,  # The current street in the hand\n",
    "        next_to_act: int,  # The index of the next player to act\n",
    "    ) -> None:\n",
    "        self.hand: Iterable[Iterable[Card]] = hand\n",
    "        self.board: Iterable[Card] = board\n",
    "        self.can_fold: bool = can_fold\n",
    "        self.can_check_or_call: bool = can_check_or_call\n",
    "        self.can_complete_bet_or_raise_to: bool = can_complete_bet_or_raise_to\n",
    "        self.players_left_in_hand: int = players_left_in_hand\n",
    "        self.hand_strength: float = hand_strength\n",
    "        self.pot_size: int = pot_size\n",
    "        self.checking_or_calling_amount: int = checking_or_calling_amount\n",
    "        self.min_completion_betting_or_raising_to_amount: int = (\n",
    "            min_completion_betting_or_raising_to_amount\n",
    "        )\n",
    "        self.street: StreetType = street\n",
    "        self.next_to_act: int = next_to_act\n",
    "\n",
    "        # calculate pot odds\n",
    "        self.pot_odds_check_or_call = checking_or_calling_amount / (\n",
    "            pot_size + checking_or_calling_amount\n",
    "        ) if can_check_or_call else 1.0\n",
    "\n",
    "        self.pot_odds_bet_or_raise = min_completion_betting_or_raising_to_amount / (\n",
    "            pot_size + min_completion_betting_or_raising_to_amount\n",
    "        ) if can_complete_bet_or_raise_to else 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "417caa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokerAgent(ABC):\n",
    "    \"\"\"A abstract player class. It's policy will be defined per-implementation.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def pi(self, observation: ObservableState) -> ActionType:\n",
    "        pass\n",
    "\n",
    "    def _compute_action(\n",
    "        self,\n",
    "        observation: ObservableState,\n",
    "        strength_to_bet_or_raise_pre_flop: float,\n",
    "        strength_to_check_or_call_pre_flop: float,\n",
    "        strength_over_pot_odds_to_bet_or_raise_post_flop: float,\n",
    "        strength_over_pot_odds_to_check_or_call_post_flop: float,\n",
    "    ) -> ActionType:\n",
    "        hand_strength = observation.hand_strength\n",
    "        pot_odds_check_or_call = observation.pot_odds_check_or_call\n",
    "        pot_odds_bet_or_raise = observation.pot_odds_bet_or_raise\n",
    "\n",
    "        if observation.street == StreetType.PRE_FLOP:\n",
    "            if (\n",
    "                hand_strength > strength_to_bet_or_raise_pre_flop\n",
    "                and observation.can_complete_bet_or_raise_to\n",
    "            ):\n",
    "                return ActionType.BET_OR_RAISE\n",
    "            elif (\n",
    "                hand_strength > strength_to_check_or_call_pre_flop\n",
    "                or observation.checking_or_calling_amount == 0\n",
    "                and observation.can_check_or_call\n",
    "            ):\n",
    "                return ActionType.CHECK_OR_CALL\n",
    "            else:\n",
    "                return ActionType.FOLD\n",
    "        else:\n",
    "            if (\n",
    "                hand_strength - pot_odds_bet_or_raise\n",
    "                > strength_over_pot_odds_to_bet_or_raise_post_flop\n",
    "                and observation.can_complete_bet_or_raise_to\n",
    "            ):\n",
    "                return ActionType.BET_OR_RAISE\n",
    "            elif (\n",
    "                hand_strength - pot_odds_check_or_call\n",
    "                > strength_over_pot_odds_to_check_or_call_post_flop\n",
    "                or observation.checking_or_calling_amount == 0\n",
    "                and observation.can_check_or_call\n",
    "            ):\n",
    "                return ActionType.CHECK_OR_CALL\n",
    "            else:\n",
    "                return ActionType.FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b991a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokerPlayer:\n",
    "    \"\"\"The information needed to represent a player in the poker environment.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, poker_agent: PokerAgent, player_index: int, stack: int = 100000\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a PokerPlayer.\n",
    "        Args:\n",
    "            poker_agent (PokerAgent): The agent controlling this player's decisions/policy.\n",
    "            player_index (int): The index of the player at the table. Needed for button rotation.\n",
    "            stack (int): The player's starting stack size.\n",
    "        \"\"\"\n",
    "        self.poker_agent = poker_agent\n",
    "        self.player_index = player_index\n",
    "        self.stack = stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a1fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedLimitTexasHoldemEnvironment:\n",
    "    \"\"\"An environment for Fixed Limit Texas Hold'em Poker\"\"\"\n",
    "\n",
    "    def __init__(self, players: list[PokerPlayer]) -> None:\n",
    "        self._pokers_equity_calculator = PokerEquityCalculator()\n",
    "        self._players = players\n",
    "        starting_stacks = [player.stack for player in self._players]\n",
    "\n",
    "        self._game = FixedLimitTexasHoldem(\n",
    "            # We're running a simulation here so no need for people to actually\n",
    "            # take these actions. These are automated by the engine.\n",
    "            automations=(\n",
    "                Automation.ANTE_POSTING,\n",
    "                Automation.BET_COLLECTION,\n",
    "                Automation.BLIND_OR_STRADDLE_POSTING,\n",
    "                Automation.CARD_BURNING,\n",
    "                Automation.HOLE_DEALING,\n",
    "                Automation.BOARD_DEALING,\n",
    "                Automation.HOLE_CARDS_SHOWING_OR_MUCKING,\n",
    "                Automation.HAND_KILLING,\n",
    "                Automation.CHIPS_PUSHING,\n",
    "                Automation.CHIPS_PULLING,\n",
    "            ),\n",
    "            ante_trimming_status=True,  # use blinds\n",
    "            raw_antes=0,\n",
    "            raw_blinds_or_straddles=(2, 4),\n",
    "            small_bet=4,\n",
    "            big_bet=8,\n",
    "            starting_board_count=1,\n",
    "        )\n",
    "\n",
    "        self._state = self._game(\n",
    "            raw_starting_stacks=starting_stacks,\n",
    "            player_count=len(self._players),\n",
    "        )\n",
    "\n",
    "    def get_next_to_act_player_index(self) -> int:\n",
    "        next_to_act = self._state.actor_indices[0]\n",
    "        return self._players[next_to_act].player_index\n",
    "\n",
    "    def _calculate_hand_strength(self) -> float:\n",
    "        next_to_act = (\n",
    "            self._state.actor_indices[0] if len(self._state.actor_indices) > 0 else None\n",
    "        )\n",
    "        hole_cards = (\n",
    "            self._state.hole_cards[next_to_act] if next_to_act is not None else []\n",
    "        )\n",
    "        hand = parse_range(\n",
    "            \"\".join([f\"{str(card.rank)}{str(card.suit)}\" for card in hole_cards])\n",
    "        )\n",
    "        return self._pokers_equity_calculator.calculate_strength(\n",
    "            hand=hand,\n",
    "            board=(\n",
    "                self._state.board_cards[0] if len(self._state.board_cards) > 0 else []\n",
    "            ),\n",
    "            players_left_in_hand=len(self._state.actor_indices),\n",
    "            sample_count=1000,\n",
    "        )\n",
    "\n",
    "    def reset(self) -> ObservableState:\n",
    "        \"\"\"\n",
    "        Resets the environment to start a new hand with the same players\n",
    "        Returns the initial observable state.\n",
    "        \"\"\"\n",
    "        # Save the old state. Unsure yet if I will use this.\n",
    "        self._old_state = copy.deepcopy(self._state)\n",
    "\n",
    "        # Rotate players for the next hand to reflect the dealer button moving\n",
    "        # around the table.\n",
    "        self._players = list(self._players[1:]) + [self._players[0]]\n",
    "\n",
    "        # Remove any bankrupt players though I will probably\n",
    "        # make the initial stacks very high to avoid this complication.\n",
    "        for i, player in enumerate(self._players):\n",
    "            if player.stack == 0:\n",
    "                del self._players[i]\n",
    "\n",
    "        current_stacks = [player.stack for player in self._players]\n",
    "\n",
    "        # Reset the game state for a new hand\n",
    "        self._state = self._game(\n",
    "            raw_starting_stacks=current_stacks,\n",
    "            player_count=len(self._players),\n",
    "        )\n",
    "\n",
    "        next_to_act = self._state.actor_indices[0]\n",
    "        hand_strength = self._calculate_hand_strength()\n",
    "        return ObservableState(\n",
    "            hand=self._state.hole_cards[next_to_act],\n",
    "            board=self._state.board_cards,\n",
    "            can_fold=self._state.can_fold(),\n",
    "            can_check_or_call=self._state.can_check_or_call(),\n",
    "            can_complete_bet_or_raise_to=self._state.can_complete_bet_or_raise_to(),\n",
    "            players_left_in_hand=len(self._state.actor_indices),\n",
    "            hand_strength=hand_strength,\n",
    "            pot_size=self._state.total_pot_amount,\n",
    "            checking_or_calling_amount=self._state.checking_or_calling_amount,\n",
    "            min_completion_betting_or_raising_to_amount=self._state.min_completion_betting_or_raising_to_amount,\n",
    "            street=StreetType.PRE_FLOP,\n",
    "            next_to_act=self.get_next_to_act_player_index(),\n",
    "        )\n",
    "\n",
    "    def action_space(self) -> list[ActionType]:\n",
    "        \"\"\"Returns the action space (what the player can do right now) for the environment.\"\"\"\n",
    "        available_actions = []\n",
    "        if self._state.can_fold():\n",
    "            available_actions.append(ActionType.FOLD)\n",
    "        if self._state.can_check_or_call():\n",
    "            available_actions.append(ActionType.CHECK_OR_CALL)\n",
    "        if self._state.can_bet_or_raise():\n",
    "            available_actions.append(ActionType.BET_OR_RAISE)\n",
    "        return available_actions\n",
    "\n",
    "    def step(self, action: ActionType) -> dict:\n",
    "        \"\"\"\n",
    "        Takes a step in the environment based on the action and returns:\n",
    "            - state: the new state of the environment\n",
    "            - reward: the reward obtained from taking the action\n",
    "            - done: whether the hand is over\n",
    "        \"\"\"\n",
    "        board_len = len(self._state.board_cards)\n",
    "        street = StreetType.PRE_FLOP\n",
    "        if board_len == 3:\n",
    "            street = StreetType.FLOP\n",
    "        elif board_len == 4:\n",
    "            street = StreetType.TURN\n",
    "        elif board_len == 5:\n",
    "            street = StreetType.RIVER\n",
    "\n",
    "        # Take the action\n",
    "        if action == ActionType.FOLD:\n",
    "            self._state.fold()\n",
    "        elif action == ActionType.CHECK_OR_CALL:\n",
    "            self._state.check_or_call()\n",
    "        elif action == ActionType.BET_OR_RAISE:\n",
    "            self._state.complete_bet_or_raise_to()\n",
    "\n",
    "        done = not self._state.status\n",
    "        rewards = None\n",
    "        if done:\n",
    "            # update player stacks\n",
    "            for i, player in enumerate(self._players):\n",
    "                player.stack = self._state.stacks[i]\n",
    "            # gather rewards\n",
    "            payoffs = self._state.payoffs\n",
    "            rewards = [0] * len(self._players)\n",
    "            # Unwind the shifting of the players to account\n",
    "            # for the dealer button moving.\n",
    "            for i, player in enumerate(self._players):\n",
    "                rewards[player.player_index] = payoffs[i]\n",
    "\n",
    "        self._old_state = copy.deepcopy(self._state)\n",
    "\n",
    "        next_to_act = (\n",
    "            self._state.actor_indices[0] if self._state.actor_indices else None\n",
    "        )\n",
    "        hand_strength = self._calculate_hand_strength() if not done else 0.0\n",
    "        observation = ObservableState(\n",
    "            hand=self._state.hole_cards[next_to_act] if not done else [],\n",
    "            board=self._state.board_cards if not done else [],\n",
    "            can_fold=self._state.can_fold(),\n",
    "            can_check_or_call=self._state.can_check_or_call(),\n",
    "            can_complete_bet_or_raise_to=self._state.can_complete_bet_or_raise_to(),\n",
    "            players_left_in_hand=(\n",
    "                len(self._state.actor_indices) if self._state.actor_indices else 0\n",
    "            ),\n",
    "            hand_strength=hand_strength,\n",
    "            pot_size=self._state.total_pot_amount,\n",
    "            checking_or_calling_amount=self._state.checking_or_calling_amount,\n",
    "            min_completion_betting_or_raising_to_amount=self._state.min_completion_betting_or_raising_to_amount,\n",
    "            street=street,\n",
    "            next_to_act=(\n",
    "                self.get_next_to_act_player_index()\n",
    "                if self._state.actor_indices\n",
    "                else None\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"observation\": observation,\n",
    "            \"done\": done,\n",
    "            \"rewards\": rewards,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fbeea",
   "metadata": {},
   "source": [
    "## Player Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4de535e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentRandom(PokerAgent):\n",
    "    \"\"\"A poker agent that takes random actions from the available action space.\"\"\"\n",
    "\n",
    "    def pi(self, observation: ObservableState) -> ActionType:\n",
    "        available_actions = []\n",
    "        if observation.can_fold:\n",
    "            available_actions.append(ActionType.FOLD)\n",
    "        if observation.can_check_or_call:\n",
    "            available_actions.append(ActionType.CHECK_OR_CALL)\n",
    "        if observation.can_complete_bet_or_raise_to:\n",
    "            available_actions.append(ActionType.BET_OR_RAISE)\n",
    "        return np.random.choice(available_actions)\n",
    "\n",
    "\n",
    "class AgentTightAggressive(PokerAgent):\n",
    "    \"\"\"\n",
    "    A poker agent that plays a tight-aggressive style. A TAG.\n",
    "    Requires quality hands to raise. Plays fewer pots.\n",
    "    \"\"\"\n",
    "\n",
    "    def pi(self, observation: ObservableState) -> ActionType:\n",
    "        return self._compute_action(\n",
    "            observation,\n",
    "            strength_to_bet_or_raise_pre_flop=0.6,\n",
    "            strength_to_check_or_call_pre_flop=0.4,\n",
    "            strength_over_pot_odds_to_bet_or_raise_post_flop=0.1,\n",
    "            strength_over_pot_odds_to_check_or_call_post_flop=0.0,\n",
    "        )\n",
    "\n",
    "class AgentLooseAggressive(PokerAgent):\n",
    "    \"\"\"\n",
    "    A poker agent that plays a loose-aggressive style. A LAG.\n",
    "    Doesn't need much to raise. Plays lots of pots.\n",
    "    \"\"\"\n",
    "\n",
    "    def pi(self, observation: ObservableState) -> ActionType:\n",
    "        return self._compute_action(\n",
    "            observation,\n",
    "            strength_to_bet_or_raise_pre_flop=0.35,\n",
    "            strength_to_check_or_call_pre_flop=0.25,\n",
    "            strength_over_pot_odds_to_bet_or_raise_post_flop=-0.05,\n",
    "            strength_over_pot_odds_to_check_or_call_post_flop=0.05,\n",
    "        )\n",
    "    \n",
    "\n",
    "class AgentTightPassive(PokerAgent):\n",
    "    \"\"\"\n",
    "    A poker agent that plays a tight-passive style. A rock.\n",
    "    Requires very strong hands to raise or bet. Plays fewer pots.\n",
    "    \"\"\"\n",
    "\n",
    "    def pi(self, observation: ObservableState) -> ActionType:\n",
    "        return self._compute_action(\n",
    "            observation,\n",
    "            strength_to_bet_or_raise_pre_flop=0.75,\n",
    "            strength_to_check_or_call_pre_flop=0.55,\n",
    "            strength_over_pot_odds_to_bet_or_raise_post_flop=0.25,\n",
    "            strength_over_pot_odds_to_check_or_call_post_flop=0.15,\n",
    "        )\n",
    "    \n",
    "class AgentLoosePassive(PokerAgent):\n",
    "    \"\"\"\n",
    "    A poker agent that plays a loose-passive style. A calling station.\n",
    "    Prefers calling to raising. Plays lots of pots.\n",
    "    \"\"\"\n",
    "\n",
    "    def pi(self, observation: ObservableState) -> ActionType:\n",
    "        return self._compute_action(\n",
    "            observation,\n",
    "            strength_to_bet_or_raise_pre_flop=0.55,\n",
    "            strength_to_check_or_call_pre_flop=0.25,\n",
    "            strength_over_pot_odds_to_bet_or_raise_post_flop=0.25,\n",
    "            strength_over_pot_odds_to_check_or_call_post_flop=0.05,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d151d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check of the agent configurations:\n",
      "-----------------------------------------------------------------\n",
      "Selected tight aggressive action:\tActionType.CHECK_OR_CALL\n",
      "Selected tight passive action:\t\tActionType.FOLD\n",
      "Selected loose aggressive action:\tActionType.BET_OR_RAISE\n",
      "Selected loose passive action:\t\tActionType.FOLD\n"
     ]
    }
   ],
   "source": [
    "# Sanity check of the coded agents rules\n",
    "observation = ObservableState(\n",
    "    hand=[[Card(Rank.ACE, Suit.SPADE), Card(Rank.ACE, Suit.HEART)]],\n",
    "    board=[\n",
    "        Card(Rank.KING, Suit.DIAMOND),\n",
    "        Card(Rank.QUEEN, Suit.SPADE),\n",
    "        Card(Rank.JACK, Suit.CLUB),\n",
    "    ],\n",
    "    can_fold=True,\n",
    "    can_check_or_call=True,\n",
    "    can_complete_bet_or_raise_to=True,\n",
    "    players_left_in_hand=4,\n",
    "    hand_strength=0.3,\n",
    "    pot_size=12,\n",
    "    checking_or_calling_amount=4,\n",
    "    min_completion_betting_or_raising_to_amount=4,\n",
    "    street=StreetType.FLOP,\n",
    "    next_to_act=0,\n",
    ")\n",
    "\n",
    "print(\"Sanity check of the agent configurations:\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "tag = AgentTightAggressive()\n",
    "action = tag.pi(observation)\n",
    "print(f\"Selected tight aggressive action:\\t{action}\")\n",
    "\n",
    "rock = AgentTightPassive()\n",
    "action = rock.pi(observation)\n",
    "print(f\"Selected tight passive action:\\t\\t{action}\")\n",
    "\n",
    "lag = AgentLooseAggressive()\n",
    "action = lag.pi(observation)\n",
    "print(f\"Selected loose aggressive action:\\t{action}\")\n",
    "\n",
    "calling_station = AgentLoosePassive()\n",
    "action = calling_station.pi(observation)\n",
    "print(f\"Selected loose passive action:\\t\\t{action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdcce60",
   "metadata": {},
   "source": [
    "## Random Agent Baseline\n",
    "\n",
    "In the following section, I will let the random agent compete against the coded agents to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22df918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  10%|█         | 1/10 [00:11<01:41, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 0.\n",
      "Player stacks: [10000, 9900, 10200, 10000, 9900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  20%|██        | 2/10 [00:14<00:51,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 1.\n",
      "Player stacks: [9992, 9900, 10212, 9996, 9900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  30%|███       | 3/10 [00:19<00:40,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 2.\n",
      "Player stacks: [9948, 9900, 10212, 9994, 9946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  40%|████      | 4/10 [00:24<00:33,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 3.\n",
      "Player stacks: [9992, 9900, 10212, 9994, 9902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  50%|█████     | 5/10 [00:35<00:37,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 4.\n",
      "Player stacks: [9980, 10112, 10112, 9994, 9802]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  60%|██████    | 6/10 [00:38<00:23,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 5.\n",
      "Player stacks: [9980, 10110, 10114, 9994, 9802]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  70%|███████   | 7/10 [00:42<00:15,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 6.\n",
      "Player stacks: [9960, 10110, 10138, 9990, 9802]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  80%|████████  | 8/10 [00:48<00:11,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 7.\n",
      "Player stacks: [9960, 10110, 10240, 9988, 9702]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.:  90%|█████████ | 9/10 [00:53<00:05,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 8.\n",
      "Player stacks: [9928, 10110, 10240, 9988, 9734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Playing hands with random agent vs. coded agents.: 100%|██████████| 10/10 [00:59<00:00,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed hand 9.\n",
      "Player stacks: [9864, 10174, 10240, 9988, 9734]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "starting_stack = 10000  # Start high to avoid going bankrupt\n",
    "player_0 = PokerPlayer(poker_agent=AgentRandom(), player_index=0, stack=starting_stack)\n",
    "player_1 = PokerPlayer(\n",
    "    poker_agent=AgentTightAggressive(), player_index=1, stack=starting_stack\n",
    ")\n",
    "player_2 = PokerPlayer(\n",
    "    poker_agent=AgentLooseAggressive(), player_index=2, stack=starting_stack\n",
    ")\n",
    "player_3 = PokerPlayer(\n",
    "    poker_agent=AgentTightPassive(), player_index=3, stack=starting_stack\n",
    ")\n",
    "player_4 = PokerPlayer(\n",
    "    poker_agent=AgentLoosePassive(), player_index=4, stack=starting_stack\n",
    ")\n",
    "players = [player_0, player_1, player_2, player_3, player_4]\n",
    "actions_taken = [[] for _ in players]\n",
    "rewards_over_time = [[] for _ in players]\n",
    "\n",
    "env = FixedLimitTexasHoldemEnvironment(players=players)\n",
    "num_hands = 10\n",
    "\n",
    "for hand in tqdm(range(num_hands), desc=\"Playing hands with random agent vs. coded agents.\"):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        next_to_act_index = observation.next_to_act\n",
    "        next_to_act = players[next_to_act_index]\n",
    "        action = next_to_act.poker_agent.pi(observation)\n",
    "\n",
    "        # Save the actions taken for graphing later\n",
    "        actions_taken[next_to_act_index].append(action)\n",
    "\n",
    "        # Take a step\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        observation = step_result[\"observation\"]\n",
    "        done = step_result[\"done\"]\n",
    "        if done:\n",
    "            # We only have rewards at the end of the hand\n",
    "            rewards = step_result[\"rewards\"]\n",
    "\n",
    "            # Save the rewards for graphing later\n",
    "            for i, reward in enumerate(rewards):\n",
    "                rewards_over_time[i].append(reward)\n",
    "\n",
    "    print(f\"Completed hand {hand}.\")\n",
    "    print(f\"Player stacks: {[player.stack for player in players]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e9facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ACTION AGGREGATES\n",
      "======================================================================\n",
      "\n",
      "Player 0 (Random):\n",
      "  Total actions: 39\n",
      "  Folds:            9 ( 23.1%)\n",
      "  Check/Calls:     13 ( 33.3%)\n",
      "  Bet/Raises:      17 ( 43.6%)\n",
      "  Total reward:  -136\n",
      "\n",
      "Player 1 (TAG):\n",
      "  Total actions: 31\n",
      "  Folds:            7 ( 22.6%)\n",
      "  Check/Calls:      6 ( 19.4%)\n",
      "  Bet/Raises:      18 ( 58.1%)\n",
      "  Total reward:  +174\n",
      "\n",
      "Player 2 (LAG):\n",
      "  Total actions: 36\n",
      "  Folds:            4 ( 11.1%)\n",
      "  Check/Calls:      9 ( 25.0%)\n",
      "  Bet/Raises:      23 ( 63.9%)\n",
      "  Total reward:  +240\n",
      "\n",
      "Player 3 (Rock):\n",
      "  Total actions: 10\n",
      "  Folds:           10 (100.0%)\n",
      "  Check/Calls:      0 (  0.0%)\n",
      "  Bet/Raises:       0 (  0.0%)\n",
      "  Total reward:  -12\n",
      "\n",
      "Player 4 (Calling Station):\n",
      "  Total actions: 52\n",
      "  Folds:            4 (  7.7%)\n",
      "  Check/Calls:     19 ( 36.5%)\n",
      "  Bet/Raises:      29 ( 55.8%)\n",
      "  Total reward:  -266\n"
     ]
    }
   ],
   "source": [
    "# Claude 4.5 prompt: print aggregates of the actions taken\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ACTION AGGREGATES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "player_names = [\"Random\", \"TAG\", \"LAG\", \"Rock\", \"Calling Station\"]\n",
    "for i, actions in enumerate(actions_taken):\n",
    "    print(f\"\\nPlayer {i} ({player_names[i]}):\")\n",
    "    fold_count = sum(1 for a in actions if a == ActionType.FOLD)\n",
    "    call_count = sum(1 for a in actions if a == ActionType.CHECK_OR_CALL)\n",
    "    raise_count = sum(1 for a in actions if a == ActionType.BET_OR_RAISE)\n",
    "    total = len(actions)\n",
    "\n",
    "    print(f\"  Total actions: {total}\")\n",
    "    print(f\"  Folds:         {fold_count:4d} ({fold_count/total*100:5.1f}%)\")\n",
    "    print(f\"  Check/Calls:   {call_count:4d} ({call_count/total*100:5.1f}%)\")\n",
    "    print(f\"  Bet/Raises:    {raise_count:4d} ({raise_count/total*100:5.1f}%)\")\n",
    "\n",
    "    # Cumulative reward\n",
    "    total_reward = sum(rewards_over_time[i])\n",
    "    print(f\"  Total reward:  {total_reward:+.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc5661-final-project-evolutionary-morl-poker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
