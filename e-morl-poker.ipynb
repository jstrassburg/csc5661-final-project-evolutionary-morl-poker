{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec10883e",
   "metadata": {},
   "source": [
    "# Evolutionary Multi-Objective Reinforcement Learning for Texas Holdem\n",
    "\n",
    "In this notebook, I will:\n",
    "\n",
    "- Define an environment to represent the game of fixed-limit Texas Holdem\n",
    "- Create six agents:\n",
    "  - Four to represent the well-known poker player archetypes: \n",
    "    - Tight-aggressive (TAG) - A normally tight player who gets aggressive with quality hands.\n",
    "    - Loose-aggressive (LAG) - A player who aggressively plays lots of hands regardless of quality.\n",
    "    - Loose-passive (calling station) - A player who plays lots of pots but doesn't aggressively raise quality hands.\n",
    "    - Tight-passive (nit or rock) - A player who plays few hands and only commits chips with quality hands.\n",
    "  - And two to represent our RL trained agents.\n",
    "\n",
    "The RL trained agents will use an evolutionary (genetic) algorithm and evolutionary reinforcement learning techniques. One will be single objective (single policy to maximize winnings) and the other will be multi-objective (a different policy for each of the playing styles noted above).\n",
    "\n",
    "I will then compare the performance of the single-objective agent to the multi-objective agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import deque\n",
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pokerkit import Automation, FixedLimitTexasHoldem\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0804763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the available actions that a player can take\n",
    "# when it is their turn to act.\n",
    "class ActionType(Enum):\n",
    "    FOLD = 0\n",
    "    CHECK_OR_CALL = 1\n",
    "    BET_OR_RAISE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a1fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedLimitTexasHoldemEnvironment:\n",
    "    \"\"\"An environment for Fixed Limit Texas Hold'em Poker\"\"\"\n",
    "\n",
    "    def __init__(self, player_count: int = 5, starting_stacks: int = 1000) -> None:\n",
    "        self._player_count = player_count\n",
    "        self._current_stacks = [starting_stacks] * player_count\n",
    "\n",
    "        self._game = FixedLimitTexasHoldem(\n",
    "            # We're running a simulation here so no need for people to actually\n",
    "            # take these actions. These are automated by the engine.\n",
    "            automations=(\n",
    "                Automation.ANTE_POSTING,\n",
    "                Automation.BET_COLLECTION,\n",
    "                Automation.BLIND_OR_STRADDLE_POSTING,\n",
    "                Automation.CARD_BURNING,\n",
    "                Automation.HOLE_DEALING,\n",
    "                Automation.BOARD_DEALING,\n",
    "                Automation.HOLE_CARDS_SHOWING_OR_MUCKING,\n",
    "                Automation.HAND_KILLING,\n",
    "                Automation.CHIPS_PUSHING,\n",
    "                Automation.CHIPS_PULLING,\n",
    "            ),\n",
    "            ante_trimming_status=True,  # use blinds\n",
    "            raw_antes=0,\n",
    "            raw_blinds_or_straddles=(2, 4),\n",
    "            small_bet=4,\n",
    "            big_bet=8,\n",
    "            starting_board_count=1,\n",
    "        )\n",
    "\n",
    "        self._state = self._game(\n",
    "            raw_starting_stacks=self._current_stacks,\n",
    "            player_count=self._player_count,\n",
    "        )\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the environment to start a new hand with the same players\"\"\"\n",
    "        # Save the old state. Unsure yet if I will use this.\n",
    "        self.old_state = copy.deepcopy(self._game.state)\n",
    "\n",
    "        # Rotate stacks for the next hand to reflect the dealer button moving\n",
    "        # around the table. I will probably need to update this to keep track\n",
    "        # of the players better.\n",
    "        self._current_stacks = list(self._state.stacks[1:]) + [self._state.stacks[0]]\n",
    "\n",
    "        # Reset the game state for a new hand\n",
    "        self._state = self._game(\n",
    "            raw_starting_stacks=self._current_stacks,\n",
    "            player_count=self._player_count,\n",
    "        )\n",
    "\n",
    "    def action_space(self) -> list[ActionType]:\n",
    "        \"\"\"Returns the action space (what the player can do right now) for the environment.\"\"\"\n",
    "        available_actions = []\n",
    "        if self._state.can_fold():\n",
    "            available_actions.append(ActionType.FOLD)\n",
    "        if self._state.can_check_or_call():\n",
    "            available_actions.append(ActionType.CHECK_OR_CALL)\n",
    "        if self._state.can_bet_or_raise():\n",
    "            available_actions.append(ActionType.BET_OR_RAISE)\n",
    "        return available_actions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc5661-final-project-evolutionary-morl-poker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
