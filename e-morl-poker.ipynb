{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec10883e",
   "metadata": {},
   "source": [
    "# Evolutionary Multi-Objective Reinforcement Learning for Texas Holdem\n",
    "\n",
    "In this notebook, I will:\n",
    "\n",
    "- Define an environment to represent the game of fixed-limit Texas Holdem\n",
    "- Create six agents:\n",
    "  - Four to represent the well-known poker player archetypes: \n",
    "    - Tight-aggressive (TAG) - A normally tight player who gets aggressive with quality hands.\n",
    "    - Loose-aggressive (LAG) - A player who aggressively plays lots of hands regardless of quality.\n",
    "    - Loose-passive (calling station) - A player who plays lots of pots but doesn't aggressively raise quality hands.\n",
    "    - Tight-passive (nit or rock) - A player who plays few hands and only commits chips with quality hands.\n",
    "  - And two to represent our RL trained agents.\n",
    "\n",
    "The RL trained agents will use an evolutionary (genetic) algorithm and evolutionary reinforcement learning techniques. One will be single objective (single policy to maximize winnings) and the other will be multi-objective (a different policy for each of the playing styles noted above).\n",
    "\n",
    "I will then compare the performance of the single-objective agent to the multi-objective agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "450346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import deque\n",
    "from collections.abc import Iterable\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from enum import Enum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pokerkit import (Automation, Card, Deck, FixedLimitTexasHoldem,\n",
    "                      StandardHighHand, calculate_hand_strength, parse_range)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0804763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the available actions that a player can take\n",
    "# when it is their turn to act.\n",
    "class ActionType(Enum):\n",
    "    FOLD = 0\n",
    "    CHECK_OR_CALL = 1\n",
    "    BET_OR_RAISE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2f730eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokerEquityCalculator:\n",
    "    \"\"\"\n",
    "    Utility class to calculate the strength of a given hand\n",
    "    on a given board using Monte Carlo simulations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._executor = ProcessPoolExecutor()\n",
    "\n",
    "    def calculate_strength(\n",
    "        self,\n",
    "        hand: Iterable[Iterable[Card]],\n",
    "        board: Iterable[Card],\n",
    "        players_left_in_hand: int = 5,\n",
    "        sample_count: int = 1000,\n",
    "    ) -> float:\n",
    "        return calculate_hand_strength(\n",
    "            player_count=players_left_in_hand,\n",
    "            hole_range=hand,\n",
    "            board_cards=board,\n",
    "            hole_dealing_count=2,\n",
    "            board_dealing_count=5,\n",
    "            deck=Deck.STANDARD,\n",
    "            hand_types=(StandardHighHand,),\n",
    "            sample_count=sample_count,\n",
    "            executor=self._executor,\n",
    "        )\n",
    "\n",
    "    def __del__(self) -> None:\n",
    "        if self._executor:\n",
    "            self._executor.shutdown(wait=True)\n",
    "            self._executor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a8bd1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservableState:\n",
    "    \"\"\"Represents the observable state for a player making game-time decisions.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hand: Iterable[Iterable[Card]],  # The player's hole cards\n",
    "        board: Iterable[Card],  # Any cards on the board\n",
    "        can_fold: bool,  # If the player can fold\n",
    "        can_check_or_call: bool,  # If the player can check or call\n",
    "        can_complete_bet_or_raise_to: bool,  # If the player can bet or raise\n",
    "        players_left_in_hand: int,  # Number of players left in the hand\n",
    "        pot_size: int,  # Current size of the pot\n",
    "        checking_or_calling_amount: int,  # Amount needed to check or call\n",
    "        min_completion_betting_or_raising_to_amount: int,  # Minimum amount to bet or raise to\n",
    "    ) -> None:\n",
    "        self.hand: Iterable[Iterable[Card]] = hand\n",
    "        self.board: Iterable[Card] = board\n",
    "        self.can_fold: bool = can_fold\n",
    "        self.can_check_or_call: bool = can_check_or_call\n",
    "        self.can_complete_bet_or_raise_to: bool = can_complete_bet_or_raise_to\n",
    "        self.players_left_in_hand: int = players_left_in_hand\n",
    "        self.pot_size: int = pot_size\n",
    "        self.checking_or_calling_amount: int = checking_or_calling_amount\n",
    "        self.min_completion_betting_or_raising_to_amount: int = (\n",
    "            min_completion_betting_or_raising_to_amount\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2a1fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedLimitTexasHoldemEnvironment:\n",
    "    \"\"\"An environment for Fixed Limit Texas Hold'em Poker\"\"\"\n",
    "\n",
    "    def __init__(self, player_count: int = 5, starting_stacks: int = 1000) -> None:\n",
    "        self._player_count = player_count\n",
    "        self._current_stacks = [starting_stacks] * player_count\n",
    "\n",
    "        self._game = FixedLimitTexasHoldem(\n",
    "            # We're running a simulation here so no need for people to actually\n",
    "            # take these actions. These are automated by the engine.\n",
    "            automations=(\n",
    "                Automation.ANTE_POSTING,\n",
    "                Automation.BET_COLLECTION,\n",
    "                Automation.BLIND_OR_STRADDLE_POSTING,\n",
    "                Automation.CARD_BURNING,\n",
    "                Automation.HOLE_DEALING,\n",
    "                Automation.BOARD_DEALING,\n",
    "                Automation.HOLE_CARDS_SHOWING_OR_MUCKING,\n",
    "                Automation.HAND_KILLING,\n",
    "                Automation.CHIPS_PUSHING,\n",
    "                Automation.CHIPS_PULLING,\n",
    "            ),\n",
    "            ante_trimming_status=True,  # use blinds\n",
    "            raw_antes=0,\n",
    "            raw_blinds_or_straddles=(2, 4),\n",
    "            small_bet=4,\n",
    "            big_bet=8,\n",
    "            starting_board_count=1,\n",
    "        )\n",
    "\n",
    "        self._state = self._game(\n",
    "            raw_starting_stacks=self._current_stacks,\n",
    "            player_count=self._player_count,\n",
    "        )\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the environment to start a new hand with the same players\"\"\"\n",
    "        # Save the old state. Unsure yet if I will use this.\n",
    "        self._old_state = copy.deepcopy(self._game.state)\n",
    "\n",
    "        # Rotate stacks for the next hand to reflect the dealer button moving\n",
    "        # around the table. I will probably need to update this to keep track\n",
    "        # of the players better.\n",
    "        self._current_stacks = list(self._state.stacks[1:]) + [self._state.stacks[0]]\n",
    "\n",
    "        # Reset the game state for a new hand\n",
    "        self._state = self._game(\n",
    "            raw_starting_stacks=self._current_stacks,\n",
    "            player_count=self._player_count,\n",
    "        )\n",
    "\n",
    "    def action_space(self) -> list[ActionType]:\n",
    "        \"\"\"Returns the action space (what the player can do right now) for the environment.\"\"\"\n",
    "        available_actions = []\n",
    "        if self._state.can_fold():\n",
    "            available_actions.append(ActionType.FOLD)\n",
    "        if self._state.can_check_or_call():\n",
    "            available_actions.append(ActionType.CHECK_OR_CALL)\n",
    "        if self._state.can_bet_or_raise():\n",
    "            available_actions.append(ActionType.BET_OR_RAISE)\n",
    "        return available_actions\n",
    "\n",
    "    def step(self, action: ActionType) -> dict:\n",
    "        \"\"\"\n",
    "        Takes a step in the environment based on the action and returns:\n",
    "            - state: the new state of the environment\n",
    "            - reward: the reward obtained from taking the action\n",
    "            - done: whether the hand is over\n",
    "        \"\"\"\n",
    "        reward = None  # TODO\n",
    "        done = False  # TODO\n",
    "\n",
    "        self._old_state = copy.deepcopy(self._state)\n",
    "\n",
    "        return {\n",
    "            \"observation\": self._state,\n",
    "            \"reward\": reward,\n",
    "            \"done\": done,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "417caa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokerAgent(ABC):\n",
    "    \"\"\"A abstract player class. It's policy will be\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def pi(self, observation: ObservableState) -> ActionType:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc5661-final-project-evolutionary-morl-poker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
